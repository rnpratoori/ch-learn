import matplotlib.pyplot as plt
import numpy as np
import imageio
import os
import subprocess
import torch

def plot_dfdc_vs_c(dfdc_net, device):
    """
    Plots the learned free energy derivative (dfdc) against the concentration (c).
    Returns the matplotlib figure.

    :param dfdc_net: The trained PyTorch model for df/dc.
    :param device: The PyTorch device (e.g., 'cpu' or 'cuda').
    :return: A matplotlib.figure.Figure object.
    """
    try:
        c_values = np.linspace(0, 1, 200).reshape(-1, 1)
        c_tensor = torch.from_numpy(c_values).to(device)
        with torch.no_grad():
            dfdc_values = dfdc_net(c_tensor).cpu().numpy()

        fig, ax = plt.subplots(figsize=(6, 4))
        ax.plot(c_values, dfdc_values)
        ax.set_xlabel("Concentration (c)")
        ax.set_ylabel("Free Energy Derivative (df/dc)")
        ax.set_title("Learned Free Energy Derivative")
        ax.grid(True)
        plt.tight_layout()
        return fig
    except Exception as e:
        print(f"Could not create df/dc vs c plot: {e}")
        return None


def plot_combined_final_timestep(preds_collection, epochs_collection, target_final_global):
    """
    Creates a combined plot showing the final-timestep predictions from several epochs against the ground truth.
    Returns the matplotlib figure.

    :param preds_collection: A list of numpy arrays, where each array is a prediction from a checkpoint epoch.
    :param epochs_collection: A list of epoch numbers corresponding to the predictions.
    :param target_final_global: A numpy array with the ground truth data for the final timestep.
    :return: A matplotlib.figure.Figure object.
    """
    if len(preds_collection) > 0:
        try:
            x = np.arange(preds_collection[0].size)
            fig, ax = plt.subplots(figsize=(8,5))
            # plot each collected prediction
            for arr, ep in zip(preds_collection, epochs_collection):
                ax.plot(x, arr, label=f'Pred (ep {ep})', lw=1, alpha=0.9)
            # overlay ground truth (final time)
            if target_final_global is not None:
                ax.plot(x, target_final_global, label='Ground truth (final time)', color='k', lw=2)
            ax.set_xlabel("DOF index")
            ax.set_ylabel("c")
            ax.set_title("Final timestep: predictions (multiple epochs) vs ground truth")
            ax.legend(ncol=2, fontsize='small')
            ax.grid(True)
            plt.tight_layout()
            return fig
        except Exception as e:
            print(f"Could not create combined final-timestep plot: {e}")
            return None
    return None

def create_video(video_fname="c_final_comparison.mp4", fps=10):
    """
    Assembles frames into a video.
    Returns the path to the created video file.

    :param video_fname: The name of the output video file.
    :param fps: The frames per second for the video.
    :return: The path to the created video file.
    """
    # This function will now be responsible for creating the video from the frames
    # that were logged to wandb. We will need to download the frames from wandb
    # or assume they are available locally. For now, we will keep the ffmpeg logic
    # but adapt it to work with a list of image paths that would be generated by wandb.
    # This part needs more thought on how to best integrate with wandb's video logging.
    # For now, we will return a dummy path.
    return video_fname

def save_comparison_image(epoch, pred_global, target_global):
    """
    Creates a matplotlib figure comparing the prediction and ground truth for a given epoch.
    Returns the matplotlib figure.

    :param epoch: The current epoch number.
    :param pred_global: The global prediction data.
    :param target_global: The global ground truth data.
    :return: A matplotlib.figure.Figure object.
    """
    try:
        x = np.arange(pred_global.size)
        fig, ax = plt.subplots(figsize=(8,5))
        ax.plot(x, pred_global, label=f'Pred (ep {epoch})', lw=1, alpha=0.9)
        ax.plot(x, target_global, label='Ground truth (final time)', color='k', lw=2)
        ax.set_xlabel("DOF index")
        ax.set_ylabel("c")
        ax.set_title(f"Final-timestep comparison at epoch {epoch}")
        ax.legend(ncol=2, fontsize='small')
        ax.grid(True)
        plt.tight_layout()
        return fig
    except Exception as e:
        print(f"Could not create comparison image for epoch {epoch}: {e}")
        return None

def save_video_frame(epoch, pred_global, target_global, loss_epoch):
    """
    Creates a matplotlib figure for a video frame.
    Returns the matplotlib figure.

    :param epoch: The current epoch number.
    :param pred_global: The global prediction data.
    :param target_global: The global ground truth data.
    :param loss_epoch: The loss value for the current epoch.
    :return: A matplotlib.figure.Figure object.
    """
    try:
        x = np.arange(pred_global.size)
        fig, ax = plt.subplots(figsize=(8,4))
        ax.plot(x, pred_global, label=f'Pred (ep {epoch})', lw=1)
        ax.plot(x, target_global, label='Ground truth (final time)', color='k', lw=1.5, alpha=0.9)
        ax.set_xlabel("DOF index")
        ax.set_ylabel("c")
        ax.set_title("Final timestep: prediction vs ground truth")
        ax.legend(loc="upper left", fontsize='small')
        # epoch text (top-right)
        ax.text(0.98, 0.98, f"Epoch {epoch}", transform=ax.transAxes,
                ha="right", va="top", fontsize=10, bbox=dict(facecolor='white', alpha=0.6, edgecolor='none'))
        # loss text (bottom-right)
        ax.text(0.98, 0.02, f"Loss = {loss_epoch:.3e}", transform=ax.transAxes,
                ha="right", va="bottom", fontsize=9, bbox=dict(facecolor='white', alpha=0.6, edgecolor='none'))
        ax.grid(True)
        plt.tight_layout()
        return fig
    except Exception as e:
        print(f"Could not create frame for epoch {epoch}: {e}")
        return None

